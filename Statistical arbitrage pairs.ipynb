{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5f28ee-8c39-40b9-a42c-efedf4854261",
   "metadata": {},
   "source": [
    "# Algorithmic Trading Strategy: Statistical Arbitrage & Cointegration\n",
    "*Author* : Cousquer Maxime  \n",
    "*Date* : 02/10/2026  \n",
    "*Context* : Personal project  \n",
    "*Stack* : Pyhton, Pandas, Numpy, Statsmodel, Seaborn, Yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f29723-4734-4c52-9373-c69f8ae8667d",
   "metadata": {},
   "source": [
    "Development of a **Market Neutral** strategy based on Pairs Trading (Mean Reversion) applied to the DJ30 and CAC40 indices (2020-2024).  \n",
    "Unlike simple correlation, this project utilizes the **Engle-Granger Two-Step approach** to identify stationary spreads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3aa48f-582d-4a2f-ac31-880db169f240",
   "metadata": {},
   "source": [
    "**Key Achievements:**\n",
    "1. **Market Scanning:** Automated testing of over 1,000 pairs to map market efficiency.\n",
    "2. **Data Cleaning:** Identification and exclusion of spurious correlations (data artifacts).\n",
    "3. **Pair Selection:** Optimization of capital allocation by selecting **Chevron (CVX) vs Exxon Mobil (XOM)** based on Half-Life mean reversion, despite other pairs having better pure statistical scores.\n",
    "4. **Risk Management:** Backtest revealing a **94% Hit Rate**, robust to standard volatility but highlighting vulnerabilities during structural breaks (COVID-19 crash)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c43e43-3744-44b9-b104-b511ef9b6592",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Theoretical Framework: Why Cointegration?\n",
    "Traditional correlation measures short-term directional movements. However, a high correlation does not imply a long-term equilibrium. To ensure the spread reverts to the mean, we test for **Cointegration**.\n",
    "\n",
    "We model the relationship between asset $Y$ and asset $X$ as:\n",
    "$$Y_t = \\alpha + \\beta X_t + \\epsilon_t$$  \n",
    "Where $\\beta$ is the Hedge ratio derivated from the OLS regression. The spread $\\epsilon$ is then tested for stationarity using the **Augmented Dickey-Fuller test (ADF)**   \n",
    "$$\\Delta \\epsilon_t = \\gamma \\epsilon_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta \\epsilon_{t-i} + u_t$$\n",
    "\n",
    "-Null hypothesis : The spread as a unit root (Non-Stationary/Random walk)  \n",
    "-Alternative : The spread is Stationary (Mean reverting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519438a-9a4a-4583-b149-9c24641df63b",
   "metadata": {},
   "source": [
    "## 2. Data Integrity & Anomaly Detection\n",
    "Before running the cointegration algorithm across the entire market, a strict data quality check was performed. Initial scans returned several \"false positive\" cointegrations with near-zero P-Values. \n",
    "\n",
    "Visual diagnostics revealed these were **Data Artifacts** (e.g., API missing values, illiquidity, or stock splits causing flat price lines). These flat or broken lines artificially trick the Augmented Dickey-Fuller test into detecting perfect stationarity.\n",
    "\n",
    "![Diagnostic](diagnostic_heatmap.png)\n",
    "\n",
    "\n",
    "*Strategic Decision: Anomalous tickers exhibiting these corrupt data patterns were strictly removed from the investment universe (Cleaned Universe) to prevent model poisoning.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb4a0c-6050-4ca9-a4c5-0638946c645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import yfinance as yf\n",
    "\n",
    "# --- 1. LA FONCTION DE SCANNER ---\n",
    "def scanner_marche(nom_indice, liste_tickers):\n",
    "    print(f\"\\n--- DÉMARRAGE DU SCANNER : {nom_indice} ---\")\n",
    "    \n",
    "    # Téléchargement\n",
    "    print(f\"Téléchargement via Yahoo Finance...\")\n",
    "    try:\n",
    "        data = yf.download(liste_tickers, start=\"2020-01-01\", end=\"2024-01-01\", auto_adjust=False, progress=False)\n",
    "        # Gestion du format MultiIndex de Yahoo (Close vs Adj Close)\n",
    "        if 'Adj Close' in data.columns:\n",
    "            data = data['Adj Close']\n",
    "        elif 'Close' in data.columns:\n",
    "            data = data['Close']\n",
    "        # Si c'est déjà un DataFrame simple\n",
    "        elif 'Adj Close' in data.columns.get_level_values(0):\n",
    "             data = data['Adj Close']\n",
    "             \n",
    "        data = data.dropna(axis=1, how='all').dropna() # Nettoyage\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de téléchargement : {e}\")\n",
    "        return None\n",
    "\n",
    "    tickers = data.columns\n",
    "    n = len(tickers)\n",
    "    print(f\" Données prêtes : {n} actions à analyser.\")\n",
    "    \n",
    "    # Matrice vide\n",
    "    pvalue_matrix = pd.DataFrame(index=tickers, columns=tickers, dtype=float)\n",
    "    \n",
    "    # Boucle de calcul\n",
    "    print(\"Calcul des cointégrations en cours...\")\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            stock_a = data.iloc[:, i]\n",
    "            stock_b = data.iloc[:, j]\n",
    "            \n",
    "            try:\n",
    "                model = sm.OLS(stock_a, sm.add_constant(stock_b))\n",
    "                res = model.fit()\n",
    "                beta = res.params.iloc[1]\n",
    "                spread = stock_a - beta * stock_b\n",
    "                p_val = adfuller(spread)[1]\n",
    "                \n",
    "                pvalue_matrix.iloc[i, j] = p_val\n",
    "                pvalue_matrix.iloc[j, i] = p_val\n",
    "            except:\n",
    "                pvalue_matrix.iloc[i, j] = 1.0\n",
    "                pvalue_matrix.iloc[j, i] = 1.0\n",
    "\n",
    "    np.fill_diagonal(pvalue_matrix.values, 1.0)\n",
    "    print(f\"Analyse terminée pour {nom_indice}.\")\n",
    "    return pvalue_matrix\n",
    "\n",
    "# --- 2. LES LISTES PROPRES  ---\n",
    "\n",
    "# DOW JONES (Cleaned Universe)\n",
    "tickers_dow_clean = [\n",
    "    \"AAPL\", \"MSFT\", \"JPM\", \"V\", \"PG\", \"WMT\", \"DIS\", \"HD\", \"JNJ\", \"KO\",\n",
    "    \"MRK\", \"MCD\", \"CSCO\", \"VZ\", \"CRM\", \"NKE\", \"AXP\", \"INTC\", \"IBM\", \"GS\",\n",
    "    \"HON\", \"CAT\", \"AMGN\", \"CVX\", \"MMM\", \"TRV\", \"UNH\", \"DOW\", \"AMZN\"\n",
    "]\n",
    "\n",
    "# CAC 40 (Cleaned Universe)\n",
    "tickers_cac_clean = [\n",
    "    \"AI.PA\", \"AIR.PA\", \"ALO.PA\", \"CS.PA\", \"BNP.PA\", \"EN.PA\", \"CAP.PA\",\n",
    "    \"CA.PA\", \"ACA.PA\", \"BN.PA\", \"DSY.PA\", \"EDEN.PA\", \"EL.PA\", \"ERF.PA\", \"RMS.PA\",\n",
    "    \"KER.PA\", \"OR.PA\", \"LR.PA\", \"MC.PA\", \"ML.PA\", \"ORA.PA\", \"RI.PA\", \"PUB.PA\",\n",
    "    \"RNO.PA\", \"SAF.PA\", \"SGO.PA\", \"SAN.PA\", \"SU.PA\", \"GLE.PA\", \"TTE.PA\", \"URW.PA\", \"VIE.PA\", \"DG.PA\", \"VIV.PA\", \"WLN.PA\"\n",
    "]\n",
    "\n",
    "# --- 3. LANCEMENT DES DEUX SCANNERS ---\n",
    "\n",
    "matrice_dow = scanner_marche(\"DOW JONES (Clean)\", tickers_dow_clean)\n",
    "matrice_cac = scanner_marche(\"CAC 40 (Clean)\", tickers_cac_clean)\n",
    "\n",
    "# --- 4. VISUALISATION ---\n",
    "if matrice_dow is not None and matrice_cac is not None:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(24, 12))\n",
    "\n",
    "    # Heatmap US\n",
    "    sns.heatmap(matrice_dow, ax=ax[0], cmap=\"RdYlGn_r\", vmin=0, vmax=0.1, cbar=False)\n",
    "    ax[0].set_title(\"DOW JONES (US) - Nettoyé\")\n",
    "\n",
    "    # Heatmap FR\n",
    "    sns.heatmap(matrice_cac, ax=ax[1], cmap=\"RdYlGn_r\", vmin=0, vmax=0.1, cbar=True, cbar_kws={'label': 'P-Value'})\n",
    "    ax[1].set_title(\"CAC 40 (FRANCE) - Nettoyé\")\n",
    "\n",
    "    plt.suptitle(\"Comparaison Finale : Structure des marchés US vs FR\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Stats\n",
    "    nb_pairs_dow = (matrice_dow < 0.05).sum().sum() / 2\n",
    "    nb_pairs_cac = (matrice_cac < 0.05).sum().sum() / 2\n",
    "    print(f\"\\ RÉSULTATS FINAUX :\")\n",
    "    print(f\" Dow Jones : {int(nb_pairs_dow)} paires valides.\")\n",
    "    print(f\" CAC 40    : {int(nb_pairs_cac)} paires valides.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed665974-bd74-45d8-99c8-154d64af139d",
   "metadata": {},
   "source": [
    "*Liste des tickers*\n",
    "* DOW JONES (Sans Boeing BA, sans WBA)\n",
    "tickers_dow_clean = [\n",
    "    \"AAPL\", \"MSFT\", \"JPM\", \"V\", \"PG\", \"WMT\", \"DIS\", \"HD\", \"JNJ\", \"KO\",\n",
    "    \"MRK\", \"MCD\", \"CSCO\", \"VZ\", \"CRM\", \"NKE\", \"AXP\", \"INTC\", \"IBM\", \"GS\",\n",
    "    \"HON\", \"CAT\", \"AMGN\", \"CVX\", \"MMM\", \"TRV\", \"UNH\", \"DOW\", \"AMZN\" ]\n",
    "\n",
    "* CAC 40 (Sans Thales HO.PA, ni Stellantis/Arcelor/STMicro et TPE/PA)\n",
    "tickers_cac_clean = [\n",
    "    \"AI.PA\", \"AIR.PA\", \"ALO.PA\", \"CS.PA\", \"BNP.PA\", \"EN.PA\", \"CAP.PA\",\n",
    "    \"CA.PA\", \"ACA.PA\", \"BN.PA\", \"DSY.PA\", \"EDEN.PA\", \"EL.PA\", \"ERF.PA\", \"RMS.PA\",\n",
    "    \"KER.PA\", \"OR.PA\", \"LR.PA\", \"MC.PA\", \"ML.PA\", \"ORA.PA\", \"RI.PA\", \"PUB.PA\",\n",
    "    \"RNO.PA\", \"SAF.PA\", \"SGO.PA\", \"SAN.PA\", \"SU.PA\", \"GLE.PA\", \"TTE.PA\", \"URW.PA\", \"VIE.PA\", \"DG.PA\", \"VIV.PA\", \"WLN.PA\" ]\n",
    "\n",
    "--------------------\n",
    "Data is fetched via Yahoo Finance API.  \n",
    "Pre-processing includes handling missing values and adjusting for stock splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853ec1c-8e88-4bf6-9f9c-170d7e81ff31",
   "metadata": {},
   "source": [
    "## 3. Structural Market Analysis: US vs France (Macro View)\n",
    "We computed the cointegration p-values for all pairs. The results are mapped below (Green = Cointegrated, $p < 0.05$).\n",
    "\n",
    "![Heatmap Comparaison](heatmap&finale.png)\n",
    "\n",
    "**Quantitative Observations:**\n",
    "* **US Market (Dow Jones):** High density of opportunities (**12.56%** of pairs are cointegrated). The US index exhibits deep sectoral homogeneity (e.g., multiple Oil giants, Tech giants), naturally fostering statistical arbitrage.\n",
    "* **French Market (CAC 40):** Low density (**7.73%**). The index is highly fragmented. Finding pairs often requires cross-sector matching (e.g., Axa/Michelin), which carries a higher fundamental risk of correlation breakdown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b07cad-1ce8-4663-879e-3c3cffd380c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Pair Selection & Strategy Implementation\n",
    "We compared two candidates: **Pepsi/Coca-Cola (PEP/KO)** and **Chevron/Exxon (CVX/XOM)**.\n",
    "\n",
    "| Metric | PEP / KO | CVX / XOM | Decision |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Correlation** | 94.5% | **97.1%** | CVX/XOM is fundamentally cleaner (Pure Energy play). |\n",
    "| **Cointegration (P-Value)** | **0.018** | 0.033 | PEP/KO is statistically stronger. |\n",
    "| **Half-Life (Mean Reversion)** | ~35 days | **~24 days** | CVX/XOM reverts faster. |\n",
    "| **Max Holding Period** | 110 days | **89 days** | CVX/XOM offers better capital efficiency. |\n",
    "\n",
    "**Selected Pair:** Chevron (CVX) vs Exxon Mobil (XOM).\n",
    "**Rationale:** We prioritize capital rotation and fundamental sector homogeneity over pure statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49065f-b24a-48d2-8100-e345a7fce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SPREAD ANALYSIS: CHEVRON VS EXXON ---\n",
    "pair_data = yf.download([\"CVX\", \"XOM\"], start=\"2020-01-01\", end=\"2024-01-01\", progress=False)['Close']\n",
    "stock_a = pair_data['CVX']\n",
    "stock_b = pair_data['XOM']\n",
    "\n",
    "# OLS Regression for Hedge Ratio\n",
    "model = sm.OLS(stock_a, sm.add_constant(stock_b)).fit()\n",
    "hedge_ratio = model.params.iloc[1]\n",
    "spread = stock_a - hedge_ratio * stock_b\n",
    "\n",
    "# Z-Score Calculation (Rolling window of 30 days for dynamic mean)\n",
    "rolling_mean = spread.rolling(window=30).mean()\n",
    "rolling_std = spread.rolling(window=30).std()\n",
    "zscore = (spread - rolling_mean) / rolling_std\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(zscore.index, zscore, label=\"Z-Score (CVX/XOM)\", color='blue')\n",
    "plt.axhline(2.0, color='red', linestyle='--', label=\"Short Spread (Overvalued)\")\n",
    "plt.axhline(-2.0, color='green', linestyle='--', label=\"Long Spread (Undervalued)\")\n",
    "plt.axhline(0, color='black', label=\"Mean\")\n",
    "plt.title(\"Z-Score Dynamics: Mean Reversion Engine\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b25d43-2ee8-47ba-819c-e166e945b6fb",
   "metadata": {},
   "source": [
    "## 5. Backtesting & Risk Management\n",
    "**Entry Rule :** Z-Score > 2.0 (Short Spread) or Z-Score < -2.0 (Long Spread).  \n",
    "**Exit Rule :** Z-Score reverts to 0.  \n",
    "**Stop Loss :** Z-Score > 4.0 (Model Break).\n",
    "\n",
    "**Results:**\n",
    "* The strategy generated **34 signals** over 5 years.  \n",
    "* **Drawdown Analysis :** The only major divergence occurred in **March 2020 (COVID-19)**. This highlights the risk of \"Fat Tail\" events where historical correlations break down due to systemic exogenous shocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1536166e-38fa-40a3-bfc1-e7353a0fbce5",
   "metadata": {},
   "source": [
    "![Z-Score](graphique_detaille_final.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef42f9-a7e6-4a31-aa3d-a310f3aba90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyser_stats_marche(matrice, nom_indice):\n",
    "    # On ne regarde que le triangle supérieur pour ne pas compter les paires en double\n",
    "    # et on exclut la diagonale\n",
    "    mask = np.triu(np.ones(matrice.shape), k=1).astype(bool)\n",
    "    valeurs = matrice.where(mask).stack() # On met tout dans une seule colonne\n",
    "    \n",
    "    total_pairs = len(valeurs)\n",
    "    \n",
    "    # 1. Paires Cointégrées (Standard) : P < 0.05\n",
    "    nb_coint = (valeurs < 0.05).sum()\n",
    "    pct_coint = (nb_coint / total_pairs) * 100\n",
    "    \n",
    "    # 2. Paires \"Pépites\" (Très fortes) : P < 0.01\n",
    "    nb_strong = (valeurs < 0.01).sum()\n",
    "    pct_strong = (nb_strong / total_pairs) * 100\n",
    "    \n",
    "    # 3. Paires \"Espoir\" (Presque bonnes) : 0.05 < P < 0.10\n",
    "    nb_weak = ((valeurs >= 0.05) & (valeurs < 0.10)).sum()\n",
    "    pct_weak = (nb_weak / total_pairs) * 100\n",
    "    \n",
    "    return {\n",
    "        \"Indice\": nom_indice,\n",
    "        \"Total Paires Testées\": total_pairs,\n",
    "        \"Paires Validées (<0.05)\": nb_coint,\n",
    "        \"Taux de Succès (%)\": round(pct_coint, 2),\n",
    "        \"Qualité 'Or' (<0.01)\": nb_strong,\n",
    "        \"Ratio Pépites (%)\": round(pct_strong, 2),\n",
    "        \"Potentiel Latent (0.05-0.10)\": nb_weak\n",
    "    }\n",
    "\n",
    "# --- CALCUL DES STATS ---\n",
    "stats_dow = analyser_stats_marche(matrice_dow, \"Dow Jones (US)\")\n",
    "stats_cac = analyser_stats_marche(matrice_cac, \"CAC 40 (FR)\")\n",
    "\n",
    "# Création du Tableau Comparatif\n",
    "df_stats = pd.DataFrame([stats_dow, stats_cac])\n",
    "df_stats = df_stats.set_index(\"Indice\")\n",
    "\n",
    "print(\"TABLEAU COMPARATIF DES MARCHÉS :\")\n",
    "display(df_stats)\n",
    "\n",
    "# --- VISUALISATION GRAPHIQUE POUR LE RAPPORT ---\n",
    "# On va tracer le % de réussite côte à côte\n",
    "ax = df_stats[[\"Taux de Succès (%)\", \"Ratio Pépites (%)\"]].plot(kind='bar', figsize=(10, 6), color=['#2ca02c', '#d62728'])\n",
    "\n",
    "plt.title(\"Densité d'Opportunités d'Arbitrage : US vs France\")\n",
    "plt.ylabel(\"Pourcentage de Paires Cointégrées\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend([\"Cointégration Standard (P<0.05)\", \"Cointégration Forte (P<0.01)\"])\n",
    "\n",
    "# Ajout des étiquettes de valeur sur les barres\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height()}%\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee733af6-4334-432b-989b-29b0c147ff1b",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "This empirical study demonstrates the power of the Engle-Granger methodology to build Market Neutral strategies. However, it also highlights three critical lessons for risk management:\n",
    "1. **Capital Efficiency vs Statistics:** The \"best\" mathematical pair is not always the most profitable to trade if it locks up capital for too long (e.g, PEP/KO vs CVX/XOM).\n",
    "2. **Model Risk & Black Swans:** The strategy achieved a high theoretical win rate (94%), but suffered its only major drawdown during the **March 2020 COVID-19 crash**. Systemic exogenous shocks can violently break historical cointegration.\n",
    "3. **Execution Reality:** While theoretical PnL is positive, real-world deployment would require modeling transaction costs, margin requirements for holding periods up to 89 days, and execution slippage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
